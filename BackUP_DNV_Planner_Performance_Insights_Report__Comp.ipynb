{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PatSteinfeld/DNV/blob/main/BackUP_DNV_Planner_Performance_Insights_Report__Comp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-NP6HK_PZNm",
        "outputId": "ac5bc48c-9529-49b8-bc4f-d4a539d71552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.21.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from io import BytesIO  # Import BytesIO for in-memory buffer handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFyLsZPi1siQ",
        "outputId": "328f8d52-0e11-4693-8e57-9c2a904f743b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from io import BytesIO  # Import BytesIO for in-memory buffer handling\n",
        "# Define the Streamlit application\n",
        "def main():\n",
        "    st.title(\"Planner Performance Insights\")\n",
        "\n",
        "    # File upload section\n",
        "    st.header(\"Upload Excel Files\")\n",
        "    old_file = st.file_uploader(\"Upload the old data Excel file\", type=[\"xlsx\"])\n",
        "    new_file = st.file_uploader(\"Upload the new data Excel file\", type=[\"xlsx\"])\n",
        "\n",
        "    if old_file and new_file:\n",
        "        # Read the uploaded files\n",
        "        old_data = pd.read_excel(old_file)\n",
        "        new_data = pd.read_excel(new_file)\n",
        "\n",
        "        # Required columns\n",
        "        required_columns = [\"Split Man-Days\", \"Activity Sub Status\", \"Split MD Date Year-Month Label\", \"Project Planner\",\"Activity Name\",\"Project Status\"]\n",
        "\n",
        "        # Check if required columns exist\n",
        "        if not all(col in old_data.columns for col in required_columns):\n",
        "            st.error(f\"The old file is missing one or more required columns: {required_columns}\")\n",
        "            return\n",
        "\n",
        "        if not all(col in new_data.columns for col in required_columns):\n",
        "            st.error(f\"The new file is missing one or more required columns: {required_columns}\")\n",
        "            return\n",
        "\n",
        "        # Filter data to include only required columns\n",
        "        od = old_data[required_columns]\n",
        "        nw = new_data[required_columns]\n",
        "\n",
        "        # Creating new column to categorize man-days\n",
        "        od[\"Type\"] = od[\"Activity Sub Status\"].apply(lambda x: \"Secured\" if x  == \"Customer accepted\" else \"Unsecured\" )\n",
        "        od[\"RC_Status\"] = od.apply(lambda row: \"RC Not available\" if row[\"Activity Name\"] == \"RC\" and row[\"Project Status\"] in [\"Quote Revision\", \"Final PA Review\"] else (\"RC available\" if row[\"Activity Name\"] == \"RC\" and row[\"Project Status\"] in [\"Reviewed\",\"Review In Progress\"] else \"Not An RC\"), axis=1)\n",
        "        nw[\"Type\"] = nw[\"Activity Sub Status\"].apply(lambda x: \"Secured\" if x  == \"Customer accepted\" else \"Unsecured\" )\n",
        "        nw[\"RC_Status\"] = od.apply(lambda row: \"RC Not available\" if row[\"Activity Name\"] == \"RC\" and row[\"Project Status\"] in [\"Quote Revision\", \"Final PA Review\"] else (\"RC available\" if row[\"Activity Name\"] == \"RC\" and row[\"Project Status\"] in [\"Reviewed\",\"Review In Progress\"] else \"Not An RC\"), axis=1)\n",
        "\n",
        "        old_res = od.groupby(['Project Planner', 'Split MD Date Year-Month Label', 'Type'])['Split Man-Days'].sum().reset_index()\n",
        "        old_res.columns = ['Planner', 'Month', 'Type', 'Man-Days']\n",
        "        old_res_1 = od.groupby(['Project Planner', 'Split MD Date Year-Month Label', 'RC_Status'])['Split Man-Days'].sum().reset_index()\n",
        "        old_res_1.columns = ['Planner', 'Month', 'RC_Status', 'RC_Man-Days']\n",
        "        new_res = nw.groupby(['Project Planner', 'Split MD Date Year-Month Label', 'Type'])['Split Man-Days'].sum().reset_index()\n",
        "        new_res.columns = ['Planner', 'Month', 'Type', 'Man-Days']\n",
        "        new_res_1 = nw.groupby(['Project Planner', 'Split MD Date Year-Month Label', 'RC_Status'])['Split Man-Days'].sum().reset_index()\n",
        "        new_res_1.columns = ['Planner', 'Month', 'RC_Status', 'RC_Man-Days']\n",
        "\n",
        "        comparison_df = pd.merge(\n",
        "            old_res,\n",
        "            new_res,\n",
        "            on=['Planner', 'Month', 'Type'],\n",
        "            suffixes=('_old', '_new'),\n",
        "            how='outer'  # Use 'outer' to include missing rows in either file\n",
        "        )\n",
        "        comparison_df_1 = pd.merge(\n",
        "            old_res_1,\n",
        "            new_res_1,\n",
        "            on=['Planner', 'Month', 'RC_Status'],\n",
        "            suffixes=('_old', '_new'),\n",
        "            how='outer'  # Use 'outer' to include missing rows in either file\n",
        "        )\n",
        "\n",
        "\n",
        "        # Calculate the difference in Split Man-Days\n",
        "        comparison_df['Man-Days_Moved'] = comparison_df['Man-Days_new'] - comparison_df['Man-Days_old']\n",
        "\n",
        "        # Pivot table to restructure the data\n",
        "        pivot_df = comparison_df.pivot_table(\n",
        "            index=['Planner', 'Month'],\n",
        "            columns='Type',\n",
        "            values=['Man-Days_old', 'Man-Days_new', 'Man-Days_Moved'], # Fixed: Changed 'Man-Day_Moved' to 'Man-Day_Difference'\n",
        "            aggfunc='sum',\n",
        "            fill_value=0  # Fill missing values with 0\n",
        "        )\n",
        "\n",
        "        # Flatten multi-level columns\n",
        "        pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
        "        pivot_df = pivot_df.reset_index()\n",
        "\n",
        "        # Use `.get` to handle potential missing columns\n",
        "        pivot_df['Total_Man-Days_old'] = pivot_df.get('Man-Days_old_Secured', 0) + pivot_df.get('Man-Days_old_Unsecured', 0)\n",
        "        pivot_df['Total_Man-Days_new'] = pivot_df.get('Man-Days_new_Secured', 0) + pivot_df.get('Man-Days_new_Unsecured', 0)\n",
        "        pivot_df['Total_Man-Days Moved'] = pivot_df['Total_Man-Days_new'] - pivot_df['Total_Man-Days_old']\n",
        "        pivot_df['secured vs portfolio(%)']=pivot_df['Man-Days_new_Unsecured']/pivot_df['Total_Man-Days_new']*100\n",
        "        # Sort by Planner and Month\n",
        "        pivot_df = pivot_df[['Planner', 'Month',\n",
        "                             'Total_Man-Days Moved',\n",
        "                             'Man-Days_Moved_Secured',\n",
        "                             'Man-Days_Moved_Unsecured',\n",
        "                             'secured vs portfolio(%)']]\n",
        "        # Sort by Planner and Month\n",
        "        pivot_df = pivot_df.sort_values(by=['Planner', 'Month']).reset_index(drop=True)\n",
        "\n",
        "        comparison_df_1['RC_Man-Day_Moved'] = comparison_df_1['RC_Man-Days_new'] - comparison_df_1['RC_Man-Days_old']\n",
        "\n",
        "\n",
        "\n",
        "        # Pivot table to restructure the data\n",
        "        pivot_df_1 = comparison_df_1.pivot_table(\n",
        "            index=['Planner', 'Month'],\n",
        "            columns='RC_Status',\n",
        "            values=['RC_Man-Days_old', 'RC_Man-Days_new', 'RC_Man-Day_Moved'],\n",
        "            aggfunc='sum',\n",
        "            fill_value=0  # Fill missing values with 0\n",
        "        )\n",
        "\n",
        "        # Flatten multi-level columns\n",
        "        pivot_df_1.columns = [f'{col[0]}_{col[1]}' for col in pivot_df_1.columns]\n",
        "        pivot_df_1 = pivot_df_1.reset_index()\n",
        "\n",
        "        # Sort by Planner and Month using the columns present in pivot_df_1\n",
        "        # This line was causing the issue, so it's removed and replaced with the line below\n",
        "        # pivot_df_1 = pivot_df.sort_values(by=['Planner', 'Month']).reset_index(drop=True)\n",
        "        pivot_df_1 = pivot_df_1.sort_values(by=['Planner', 'Month']).reset_index(drop=True)  # Sorting pivot_df_1\n",
        "\n",
        "        # Select desired columns from pivot_df_1. Note the changes in column names\n",
        "        pivot_df_1 = pivot_df_1[['Planner', 'Month',\n",
        "\n",
        "                              'RC_Man-Day_Moved_RC Not available',\n",
        "                              'RC_Man-Day_Moved_RC available']]\n",
        "\n",
        "        # Sort by Planner and Month\n",
        "        pivot_df_1 = pivot_df_1.sort_values(by=['Planner', 'Month']).reset_index(drop=True)\n",
        "\n",
        "\n",
        "        # Display results\n",
        "        st.header(\"Comparison Results\")\n",
        "        st.subheader(\"Month-wise Planner Performance Comparison\")\n",
        "        st.dataframe(pivot_df)\n",
        "\n",
        "        # Convert DataFrame to Excel in-memory buffer\n",
        "        output = BytesIO()\n",
        "        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n",
        "            pivot_df.to_excel(writer, index=False, sheet_name='Comparison Results')\n",
        "        processed_data = output.getvalue()\n",
        "\n",
        "        # Allow download of results\n",
        "        st.download_button(\n",
        "            label=\"Download Comparison Results as Excel\",\n",
        "            data=processed_data,\n",
        "            file_name=\"comparison_results.xlsx\",\n",
        "            mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
        "        )\n",
        "        # Display results for \"RC Specific\"\n",
        "        st.header(\"RC Specific\")\n",
        "        st.subheader(\"Month-wise Planner RC Performance\")\n",
        "        st.dataframe(pivot_df_1) # Corrected variable name to pivot_df_1\n",
        "\n",
        "        # Convert \"RC Specific\" DataFrame to Excel in-memory buffer\n",
        "        output_2 = BytesIO()\n",
        "        with pd.ExcelWriter(output_2, engine='openpyxl') as writer:\n",
        "            pivot_df_1.to_excel(writer, index=False, sheet_name='RC Performance') # Corrected variable name to pivot_df_1\n",
        "        processed_data_2 = output_2.getvalue()\n",
        "\n",
        "        # Allow download of \"RC Specific\" results\n",
        "        st.download_button(\n",
        "            label=\"Download RC Specific Results as Excel\",\n",
        "            data=processed_data_2,\n",
        "            file_name=\"rc_specific_results.xlsx\",\n",
        "            mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyZJ0NXDPza2",
        "outputId": "0a1f90fd-0c13-4785-bc7a-e99941843a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.46.161.40"
          ]
        }
      ],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IWl5aMFQRuzz"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqyxdRZtRmDp",
        "outputId": "b472c990-c445-4bca-f943-5a0b9426cd0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0Kyour url is: https://dark-sites-watch.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "l5IWdO7Dy7g9",
        "outputId": "dbb29a3f-2195-4214-e7bc-ba4afac9ff61"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-8-02f596dd163f>, line 128)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-02f596dd163f>\"\u001b[0;36m, line \u001b[0;32m128\u001b[0m\n\u001b[0;31m    st.header(\"Comparison Results\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from io import BytesIO  # Import BytesIO for in-memory buffer handling\n",
        "# Define the Streamlit application\n",
        "def main():\n",
        "    st.title(\"Planner Performance Insights\")\n",
        "\n",
        "    # File upload section\n",
        "    st.header(\"Upload Excel Files\")\n",
        "    old_file = st.file_uploader(\"Upload the old data Excel file\", type=[\"xlsx\"])\n",
        "    new_file = st.file_uploader(\"Upload the new data Excel file\", type=[\"xlsx\"])\n",
        "\n",
        "    if old_file and new_file:\n",
        "        # Read the uploaded files\n",
        "        old_data = pd.read_excel(old_file)\n",
        "        new_data = pd.read_excel(new_file)\n",
        "\n",
        "        # Required columns\n",
        "        required_columns = [\"Split Man-Days\", \"Activity Sub Status\", \"Split MD Date Year-Month Label\", \"Project Planner\",\"Activity Name\",\"Project Status\"]\n",
        "\n",
        "        # Check if required columns exist\n",
        "        if not all(col in old_data.columns for col in required_columns):\n",
        "            st.error(f\"The old file is missing one or more required columns: {required_columns}\")\n",
        "            return\n",
        "\n",
        "        if not all(col in new_data.columns for col in required_columns):\n",
        "            st.error(f\"The new file is missing one or more required columns: {required_columns}\")\n",
        "            return\n",
        "\n",
        "        # Filter data to include only required columns\n",
        "        od = old_data[required_columns]\n",
        "        nw = new_data[required_columns]\n",
        "\n",
        "        # Creating new column to categorize man-days\n",
        "        od[\"Type\"] = od[\"Activity Sub Status\"].apply(lambda x: \"Secured\" if x  == \"Customer accepted\" else \"Unsecured\" )\n",
        "        od[\"RC_Status\"] = od.apply(lambda row: \"RC Not available\" if row[\"Activity Name\"] == \"RC\" and row[\"Project Status\"] in [\"Quote Revision\", \"Final PA Review\"] else (\"RC available\" if row[\"Activity Name\"] == \"RC\" and row[\"Project Status\"] in [\"Reviewed\",\"Review In Progress\"] else \"Not An RC\"), axis=1)\n",
        "        nw[\"Type\"] = nw[\"Activity Sub Status\"].apply(lambda x: \"Secured\" if x  == \"Customer accepted\" else \"Unsecured\" )\n",
        "        nw[\"RC_Status\"] = od.apply(lambda row: \"RC Not available\" if row[\"Activity Name\"] == \"RC\" and row[\"Project Status\"] in [\"Quote Revision\", \"Final PA Review\"] else (\"RC available\" if row[\"Activity Name\"] == \"RC\" and row[\"Project Status\"] in [\"Reviewed\",\"Review In Progress\"] else \"Not An RC\"), axis=1)\n",
        "\n",
        "        old_res = od.groupby(['Project Planner', 'Split MD Date Year-Month Label', 'Type'])['Split Man-Days'].sum().reset_index()\n",
        "        old_res.columns = ['Planner', 'Month', 'Type', 'Man-Days']\n",
        "        old_res_1 = od.groupby(['Project Planner', 'Split MD Date Year-Month Label', 'RC_Status'])['Split Man-Days'].sum().reset_index()\n",
        "        old_res_1.columns = ['Planner', 'Month', 'RC_Status', 'RC_Man-Days']\n",
        "        new_res = nw.groupby(['Project Planner', 'Split MD Date Year-Month Label', 'Type'])['Split Man-Days'].sum().reset_index()\n",
        "        new_res.columns = ['Planner', 'Month', 'Type', 'Man-Days']\n",
        "        new_res_1 = nw.groupby(['Project Planner', 'Split MD Date Year-Month Label', 'RC_Status'])['Split Man-Days'].sum().reset_index()\n",
        "        new_res_1.columns = ['Planner', 'Month', 'RC_Status', 'RC_Man-Days']\n",
        "\n",
        "        comparison_df = pd.merge(\n",
        "            old_res,\n",
        "            new_res,\n",
        "            on=['Planner', 'Month', 'Type'],\n",
        "            suffixes=('_old', '_new'),\n",
        "            how='outer'  # Use 'outer' to include missing rows in either file\n",
        "        )\n",
        "        comparison_df_1 = pd.merge(\n",
        "            old_res_1,\n",
        "            new_res_1,\n",
        "            on=['Planner', 'Month', 'RC_Status'],\n",
        "            suffixes=('_old', '_new'),\n",
        "            how='outer'  # Use 'outer' to include missing rows in either file\n",
        "        )\n",
        "\n",
        "\n",
        "        # Calculate the difference in Split Man-Days\n",
        "        comparison_df['Man-Days_Moved'] = comparison_df['Man-Days_new'] - comparison_df['Man-Days_old']\n",
        "\n",
        "        # Pivot table to restructure the data\n",
        "        pivot_df = comparison_df.pivot_table(\n",
        "            index=['Planner', 'Month'],\n",
        "            columns='Type',\n",
        "            values=['Man-Days_old', 'Man-Days_new', 'Man-Days_Moved'], # Fixed: Changed 'Man-Day_Moved' to 'Man-Day_Difference'\n",
        "            aggfunc='sum',\n",
        "            fill_value=0  # Fill missing values with 0\n",
        "        )\n",
        "\n",
        "        # Flatten multi-level columns\n",
        "        pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
        "        pivot_df = pivot_df.reset_index()\n",
        "\n",
        "        # Use `.get` to handle potential missing columns\n",
        "        pivot_df['Total_Man-Days_old'] = pivot_df.get('Man-Days_old_Secured', 0) + pivot_df.get('Man-Days_old_Unsecured', 0)\n",
        "        pivot_df['Total_Man-Days_new'] = pivot_df.get('Man-Days_new_Secured', 0) + pivot_df.get('Man-Days_new_Unsecured', 0)\n",
        "        pivot_df['Total_Man-Days Moved'] = pivot_df['Total_Man-Days_new'] - pivot_df['Total_Man-Days_old']\n",
        "        pivot_df['secured vs portfolio(%)']=pivot_df['Man-Days_new_Unsecured']/pivot_df['Total_Man-Days_new']*100\n",
        "        # Sort by Planner and Month\n",
        "        pivot_df = pivot_df[['Planner', 'Month',\n",
        "                             'Total_Man-Days Moved',\n",
        "                             'Man-Days_Moved_Secured',\n",
        "                             'Man-Days_Moved_Unsecured',\n",
        "                             'secured vs portfolio(%)']]\n",
        "        # Sort by Planner and Month\n",
        "        pivot_df = pivot_df.sort_values(by=['Planner', 'Month']).reset_index(drop=True)\n",
        "\n",
        "        comparison_df_1['RC_Man-Day_Moved'] = comparison_df_1['RC_Man-Days_new'] - comparison_df_1['RC_Man-Days_old']\n",
        "\n",
        "\n",
        "\n",
        "        # Pivot table to restructure the data\n",
        "        pivot_df_1 = comparison_df_1.pivot_table(\n",
        "            index=['Planner', 'Month'],\n",
        "            columns='RC_Status',\n",
        "            values=['RC_Man-Days_old', 'RC_Man-Days_new', 'RC_Man-Day_Moved'],\n",
        "            aggfunc='sum',\n",
        "            fill_value=0  # Fill missing values with 0\n",
        "        )\n",
        "\n",
        "        # Flatten multi-level columns\n",
        "        pivot_df_1.columns = [f'{col[0]}_{col[1]}' for col in pivot_df_1.columns]\n",
        "        pivot_df_1 = pivot_df_1.reset_index()\n",
        "\n",
        "        # Sort by Planner and Month using the columns present in pivot_df_1\n",
        "        # This line was causing the issue, so it's removed and replaced with the line below\n",
        "        # pivot_df_1 = pivot_df.sort_values(by=['Planner', 'Month']).reset_index(drop=True)\n",
        "        pivot_df_1 = pivot_df_1.sort_values(by=['Planner', 'Month']).reset_index(drop=True)  # Sorting pivot_df_1\n",
        "\n",
        "        # Select desired columns from pivot_df_1. Note the changes in column names\n",
        "        pivot_df_1 = pivot_df_1[['Planner', 'Month',\n",
        "                              'RC_Man-Day_Moved_Not An RC',\n",
        "                              'RC_Man-Day_Moved_RC Not available',\n",
        "                              'RC_Man-Day_Moved_RC available']]\n",
        "\n",
        "        # Sort by Planner and Month\n",
        "        pivot_df_1 = pivot_df_1.sort_values(by=['Planner', 'Month']).reset_index(drop=True)\n",
        "\n",
        "\n",
        "        # Display results\n",
        "        st.header(\"Comparison Results\")\n",
        "        st.subheader(\"Month-wise Planner Performance Comparison\")\n",
        "        st.dataframe(pivot_df)\n",
        "\n",
        "        # Convert DataFrame to Excel in-memory buffer\n",
        "        output = BytesIO()\n",
        "        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n",
        "            pivot_df.to_excel(writer, index=False, sheet_name='Comparison Results')\n",
        "        processed_data = output.getvalue()\n",
        "\n",
        "        # Allow download of results\n",
        "        st.download_button(\n",
        "            label=\"Download Comparison Results as Excel\",\n",
        "            data=processed_data,\n",
        "            file_name=\"comparison_results.xlsx\",\n",
        "            mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
        "        )\n",
        "        # Display results for \"RC Specific\"\n",
        "        st.header(\"RC Specific\")\n",
        "        st.subheader(\"Month-wise Planner RC Performance\")\n",
        "        st.dataframe(pivot_df_1) # Corrected variable name to pivot_df_1\n",
        "\n",
        "        # Convert \"RC Specific\" DataFrame to Excel in-memory buffer\n",
        "        output_2 = BytesIO()\n",
        "        with pd.ExcelWriter(output_2, engine='openpyxl') as writer:\n",
        "            pivot_df_1.to_excel(writer, index=False, sheet_name='RC Performance') # Corrected variable name to pivot_df_1\n",
        "        processed_data_2 = output_2.getvalue()\n",
        "\n",
        "        # Allow download of \"RC Specific\" results\n",
        "        st.download_button(\n",
        "            label=\"Download RC Specific Results as Excel\",\n",
        "            data=processed_data_2,\n",
        "            file_name=\"rc_specific_results.xlsx\",\n",
        "            mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJ77r7GH2bL96P367105yt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
